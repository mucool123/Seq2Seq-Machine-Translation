{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmYGVziz50tu"
   },
   "source": [
    "- Remove non alphanumeric characters for simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "FOwRggVcwtzP"
   },
   "outputs": [],
   "source": [
    "from transformer import Transformer # this is the transformer.py file\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "6TApzOj5xCwR"
   },
   "outputs": [],
   "source": [
    "english_file = 'train100_en.txt' # only 100 instances are used for experiment\n",
    "marathi_file = 'train100_mr.txt' # only 100 instances are used for experiment\n",
    "\n",
    "# Generated this by filtering Appendix code\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PADDING>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "marathi_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', \n",
    "                      'ँ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ', \n",
    "                      'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ॠ', 'ऌ', 'ऎ', 'ए', 'ऐ', 'ऒ', 'ओ', 'औ', \n",
    "                      'क', 'ख', 'ग', 'घ', 'ङ', \n",
    "                      'च', 'छ', 'ज', 'झ', 'ञ', \n",
    "                      'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                      'त', 'थ', 'द', 'ध', 'न', \n",
    "                      'प', 'फ', 'ब', 'भ', 'म', \n",
    "                      'य', 'र', 'ऱ', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', \n",
    "                      '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ॐ', '।', '॥', '॰', 'ॱ', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@',\n",
    "                        '[', '\\\\', ']', '^', '_', '`', \n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                        'y', 'z', \n",
    "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "gA8ESmCrNoc7"
   },
   "outputs": [],
   "source": [
    "index_to_marathi = {k:v for k,v in enumerate(marathi_vocabulary)}\n",
    "marathi_to_index = {v:k for k,v in enumerate(marathi_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "9SYGjRdoxRg-"
   },
   "outputs": [],
   "source": [
    "with open(english_file, 'r') as file:\n",
    "    english_sentences = file.readlines()\n",
    "with open(marathi_file, 'r') as file:\n",
    "    marathi_sentences = file.readlines()\n",
    "\n",
    "# Limit Number of sentences\n",
    "TOTAL_SENTENCES = 99\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "marathi_sentences = marathi_sentences[:TOTAL_SENTENCES]\n",
    "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
    "marathi_sentences = [sentence.rstrip('\\n') for sentence in marathi_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUB-BkgFxXfM",
    "outputId": "bcf7e19c-d1df-4b69-bdfa-eb74ac1a4338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['today, asean and india enjoy multi-faceted cooperation across aseans political-security, economic and socio-cultural pillars. prime minister narendra modis act east policy and 3-c (commerce, connectivity, culture) formula for strengthening engagement with asean speaks to our broad-based cooperation.',\n",
       " 'for us in india, aseans continuance in this role is vitally important. indeed, indias relationship with the asean is a central pillar of our act east policy.',\n",
       " 'we need to put faith in his reminders.',\n",
       " 'presently elections are being held in gujarat.',\n",
       " 'this will aim to pool research and technological advancements in the field of solar energy, to improve its accessibility to the poorest of the poor, and in the remotest of locations.',\n",
       " 'similarly, instead of letting ourselves become overwhelmed by the present wickedness of satans rule or impatient about when it will end, let us put faith in the unseen things that will last forever.',\n",
       " 'so much hard work!',\n",
       " 'school students also took part in the procession.',\n",
       " 'the phone will also have expandable storage up to 512 gb.',\n",
       " 'he says india is special to him.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OT-aznAxc5U",
    "outputId": "716c4145-fdc2-4bb0-e883-c3dcad30c2da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['आज आसियान आणि भारत, आसियानचे राजनीतिक- सुरक्षा आणि आर्थिक तसेच सामाजिक, सांस्कृतिक स्तंभांचा अनेक मार्गांनी सहयोग, सहकार्य यांचा लाभ घेत आहेत.पंतप्रधान नरेंद्र मोदी यांच्या ‘अॅक्ट ईस्ट’ या कार्यक्रमामुळे आणि आसियानबरोबर मजबूत संबंध प्रस्थापित करण्यासाठी ‘तीन -सी’( कॉमर्स-वाणिज्य, कनेक्टिव्हिटी- संपर्क यंत्रणा, कल्चर -संस्कृती) आमच्या दृष्टीने व्यापक सहयोगाचे सर्वोत्तम उदाहरण आहेत, असे म्हणता येईल.',\n",
       " 'आसियान राष्ट्र समुहातील देशांशी भारताचे उत्तम संबंध असून, सुरक्षाविषयक यंत्रणांच्या सक्षमीकरणासंदर्भात सर्व देशांच्या परस्पर संवादाची आवश्यकता असल्याचे त्यांनी अधोरेखित केले.',\n",
       " '[ ७ पानांवरील चित्र]',\n",
       " 'दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.',\n",
       " 'यामुळे सौर ऊर्जा क्षेत्रातल्या संशोधनाला आणि त्यातील सुधारणांना वाव मिळण्याची आणि दुर्गम भागातील गरिबातील गरिबाला वीज उपलब्ध होण्याची अपेक्षा पंतप्रधानांनी व्यक्त केली.',\n",
       " 'त्याने आपल्या एकुलत्या एका पुत्राला “सैतानाची कृत्ये नष्ट ” करण्यासाठी आणि सैतानामुळे मानवांचे झालेले नुकसान भरून काढण्यासाठी पाठवले.',\n",
       " 'एवढे कष्ट!',\n",
       " 'पालखी सोहळ्यामध्ये शालेय विद्यार्थिनींचे पथकही सहभागी झाले होते.',\n",
       " 'तसंच 512 जीबी पर्यंत या फोनची मेमरी वाढवता येणार आहे.',\n",
       " 'विराट म्हणतो की, भारत आणि त्याच्यासाठी धोनी खास आहे.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marathi_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8VAutsTxlaR",
    "outputId": "ff8fba72-020d-4f0c-b3c5-31c102b6fe9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length marathi: 168.36\n",
      "97th percentile length English: 198.24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length marathi: {np.percentile([len(x) for x in marathi_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HG9ezqvaxl4b",
    "outputId": "d13be774-ca07-4333-856e-76186f71caae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 99\n",
      "Number of valid sentences: 30\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(marathi_sentences)):\n",
    "    marathi_sentence, english_sentence = marathi_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(marathi_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(marathi_sentence, marathi_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(marathi_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "o80QDn4CxsV7"
   },
   "outputs": [],
   "source": [
    "marathi_sentences = [marathi_sentences[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35xhLztQiLIQ",
    "outputId": "aa70ad04-2e45-4c78-c852-61e92c51a96a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.',\n",
       " 'एवढे कष्ट!',\n",
       " 'विराट म्हणतो की, भारत आणि त्याच्यासाठी धोनी खास आहे.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marathi_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "xqOFnclmyxAE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "mr_vocab_size = len(marathi_vocabulary)\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          ffn_hidden,\n",
    "                          num_heads, \n",
    "                          drop_prob, \n",
    "                          num_layers, \n",
    "                          max_sequence_length,\n",
    "                          mr_vocab_size,\n",
    "                          english_to_index,\n",
    "                          marathi_to_index,\n",
    "                          START_TOKEN, \n",
    "                          END_TOKEN, \n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zc2hYQk9yxX0",
    "outputId": "c060f588-6a2e-4179-9475-5acafd641f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(71, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(114, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm3): LayerNormalization()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=114, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "asUJX-STy7fg"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, english_sentences, marathi_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.marathi_sentences = marathi_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.marathi_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "-auNWjkdzDge"
   },
   "outputs": [],
   "source": [
    "dataset = TextDataset(english_sentences, marathi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roH2A4m4zF4z",
    "outputId": "f4353aa8-2f37-43b6-be0f-12aab9a35145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGeHNlzozIGF",
    "outputId": "ec3596fe-feee-426c-dce8-373fb07080fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('so much hard work!', 'एवढे कष्ट!')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "5YDttjQ0zMrv"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EnjHKB1zM8Y",
    "outputId": "1a825e56-6706-46ee-85b5-ed7f0ac657fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('presently elections are being held in gujarat.', 'so much hard work!', 'he says india is special to him.', 'for me, the priority is to put every penny received from the taxes paid by the honest and hard working tax payers to right use.', 'monitoring progress of capacity augmentation works required to increase speeds.', 'but a lot of it is.', 'we call it india.', 'it also reduces the risk of stroke.', 'this has costs.', 'maharashtra has the highest number of corona patients.', 'issues should be addressed.', 'up in zarephath, a phoenician coastal town, a poor widow showed hospitality to the prophet.', 'great power', 'when drought occurs, rainfall gets reduced.', 'but are all these claims really true?', 'we want to be worthy, humble servants of god. how can we attain that goal?', 'india is no exception to this.', 'but the issue is how to achieve it.', 'it is the most memorable moment in my life.', 'money is just a means to live.', 'but couldnt speak further.', 'support to army', 'the incident took place around three in the morning.', 'look what it says.', 'its nothing new, and its nothing unique.', 'the mixture is easy to prepare.', 'he scored 17 sixes in the tournament.', 'is inflation rising?', 'light and water', 'i learnt sword fighting and horse riding.'), ('दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.', 'एवढे कष्ट!', 'विराट म्हणतो की, भारत आणि त्याच्यासाठी धोनी खास आहे.', 'त्याने सरकारला दिलेल्या प्रत्येक पैशा पैशाचा अगदी योग्य विनियोग केला गेला पाहिजे, असे मला वाटते.', 'गती वाढवण्यासाठी क्षमता वाढवण्याच्या कामाच्या प्रगतीवर देखरेख.', 'पण बरीच आहे.', 'आम्ही त्याला भारतात बोलावून घेतले.', 'हृदयविकाराचा झटका येण्याचा धोकादेखील कमी होतो.', 'या खर्चाचा समावेश आहे.', 'महाराष्ट्रात कोरोनाचा सर्वाधिक कोरोना रुग्ण आहेत.', 'त्यात येणारे प्रश्न सोडवावे लागतात.', 'इस्राएलच्या उत्तरेकडे असलेल्या सारफथ नगरात एक गरीब विधवा राहायची.', 'अदभुत शक्ती', 'पाऊस कमी झाला की, दुष्काळ पडतो.', 'पण या कॅडबरी खरच प्रमाणित आहेत का?', 'आपण देवाला शोभतील असे त्याचे नम्र सेवक होऊ इच्छितो.', 'भारतीय उद्योगजगतदेखील याला अपवाद नाही.', 'पण त्याची तोड कशी करायची, हा प्रश्न आहे.', 'माझ्या आयुष्यातील हा सर्वात अविस्मरणीय क्षण आहे.', 'पैसा हा जीवन चरितार्थाचे साधन आहे.', 'मात्र, याबाबत अधिक बोलू शकत नाही.', 'आर्मीचा मोलाचा सपोर्ट', 'पहाटे तीनच्या सुमारास ही घटना घडली.', 'म्हटल काय आहे ते बघाव जरा.', 'यात वेगळे आणि नवीन काही नाही.', 'मिश्रण तयार करण्यासाठी सूचना अगदी सोपे आहे.', 'या सामन्यात त्याने एकूण 17 बिनतोड सर्व्हिस केल्या.', 'महागाई वाढणार?', 'पाणी आणि मेणबत्त्या', 'तलवारबाजी आणि घोडेस्वारी शिकतेय.')]\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "XnanjzqtzQi8"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=marathi_to_index[PADDING_TOKEN],\n",
    "                                reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "_saWU5QmVem2"
   },
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, mr_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, mr_sentence_length = len(eng_batch[idx]), len(mr_batch[idx])\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "      mr_chars_to_padding_mask = np.arange(mr_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, mr_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, mr_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, mr_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdgtTSKvwN9_"
   },
   "source": [
    "Modify mask such that the padding tokens cannot look ahead.\n",
    "In Encoder, tokens before it should be -1e9 while tokens after it should be -inf.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLcXI4wkMLck"
   },
   "source": [
    "Note the target mask starts with 2 rows of non masked items: https://github.com/SamLynnEvans/Transformer/blob/master/Beam.py#L55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ju59VDGLuOqf",
    "outputId": "0ad34e31-521a-4ca2-f444-26b5374946f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Iteration 0 : 5.354878902435303\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ు*मऽयऽजमऽऽऽऽबब<बज<भथऽ'बबबबबबबब#जन<<<बओ<ठी<ीी्छीओ#<जजज#ठ्न्ीीन3ीीीनीइइीीी####ीी#ी<<ుीीनుीीीीीుडు#ుजननननडుుडऽుी<<<<डडजनీ<<नుుుుऽबीीन<नీ<ीऽज<जीుीीऋउजठजजजजऽञుుऽ<ऽजजుऋऽుनऽऽजडीीుుबजनऽजीथनथऽजऽऽ#नननుनजथजनजननन\n",
      "Evaluation translation (should we go to the mall?) : ('ााााा         ााााा                  ााा    ाााााााााा                          ््््ाा      ििििििििनन्           ाा   ाा््                               ाााााााा         ाााा    ाााााााा     ा्््    ',)\n",
      "-------------------------------------------\n",
      "Epoch 1\n",
      "Iteration 0 : 4.435696601867676\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ा्ाा्ा्ाा   ्ा ाााा   ा बाब    ाााा्ाााीााा ्ााााााााा  ा्ीीीीीीीााी ीाी ी्ीीीी्ओ््ीाीी ीుीीििि्िीीनుननीकीीीीी डडडाा्न>ााा्ाा ीी मीీీీీऱ  ीीीीीीनाీी ˌ ˌीााथााााक्ा#नीుी ीााााा ी नााााााानााा ीीीााननान\n",
      "Evaluation translation (should we go to the mall?) : ('ाााा           ााा                                                                                                                                         ाााााा           ााा     ााााा               ',)\n",
      "-------------------------------------------\n",
      "Epoch 2\n",
      "Iteration 0 : 4.222436904907227\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ्ाा            ाााा      ाा      ा  ा         ाा   ाा ा    ाी   ााा         ी  ्  ्ीाा    ी ाािििि् लन व  ी   ी ाााा  ा ाा                   ी   ााााा ीे ााााााा ा ा      ाााा  ा   ाा ा  ाा ा ाााा    \n",
      "Evaluation translation (should we go to the mall?) : ('ाााााा        ाााााा    ााा    ााा  ााााा   ाााााााााा   ााा     ााा   ाा  ीी   ््््ाा       विििीीीरीीी         ााा  ाााा                      ेेेीीी    ाााााााााररर    ाााााा  ाााााााााा  ााा््््   ',)\n",
      "-------------------------------------------\n",
      "Epoch 3\n",
      "Iteration 0 : 3.8963327407836914\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ्ााा   राा ््् ााााता ्ााला ाााारा   ाा ार ााासााा ाााााास  े ीीीीाीीीााीीीीााा्न ््ीा ि  ीीा ि्ीीाीीकीीीीीरसी ककाकीआीाााााा  े ीी  ी   वव ीी   ीेी ीीीेवााेााााााकाेीी्् ाकााा ीीााााााााा ााा ाा्ाका ा\n",
      "Evaluation translation (should we go to the mall?) : ('ेेेेतररररररतत््ारररततततललललल  ररररकरररीीीीीीससीीीीेेेेसससीीीेेेेेससससीीीीीीीीवव्््््वववव ीीवववववववीीककलीीीीससीीककककसेेेेे््  ेेेेेेेेेववव  ीीीेेेेेेेीेेेेेेेेेककककरेेेी््ररराा्  ाााााााााा  ीीी््््   ',)\n",
      "-------------------------------------------\n",
      "Epoch 4\n",
      "Iteration 0 : 3.848891019821167\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ेे्वयरतला ाकरतर्ारततस लर्लतलत्सरतका्सााीरी्ाेीसीीकेेेसससस्ीकीेीेेससीीीीीवीसी्ेीवीीीीवलवीककवकवीववीवीीकसललवसकससीीकककककेकेीेाा ेेेेे.ेेेव \n",
      "Evaluation translation (should we go to the mall?) : ('ेेेततततेततततततततततततततततततततततततततेेेीीीीीेेेसीीीेेेेेेससीेेेेेेेेेेेीीीवववववेेेे््वववववतीीवववववववववकककवववककसीकेकककेेेेेेेेेेेेेेेेेे<END>',)\n",
      "-------------------------------------------\n",
      "Epoch 5\n",
      "Iteration 0 : 3.8151159286499023\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: वेेेेेेरतेात्ततताातततकाासततत कतवतेतेरहातीीेेीसीसीेेेेेसेसेकेकसेीसेसाकसेासीीवेेेेककवीहलवीीक कविहहकिवसकनलवलीलककवकककेककककेेेेेेेेेेेेेेेव\n",
      "Evaluation translation (should we go to the mall?) : ('ाााातततााााततततााातततत  ााा   ााताााााााीी  ाााााेेेेेेससीाेेेेेेेाा<END>',)\n",
      "-------------------------------------------\n",
      "Epoch 6\n",
      "Iteration 0 : 3.6696934700012207\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ाेयतेाेत  ातातााकत तसह त ोा  ाह्ाे ताायह से  \n",
      "Evaluation translation (should we go to the mall?) : ('ाााााााााााााााााााा    ााा    ााा   ााा     ाााााााा     ाा                       ााा       वहहीीीीीहहह         <END>',)\n",
      "-------------------------------------------\n",
      "Epoch 7\n",
      "Iteration 0 : 3.592928171157837\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ्ेाााााा या ता ा रा  ा ा ा   ा ााा.  याा  ेाासा  का  ा  ा ाा ेेेाा\n",
      "Evaluation translation (should we go to the mall?) : ('ााााा          ाााा                                                                 ा                                                                     ााााााा          ाााा     ााााााा     ााा     ',)\n",
      "-------------------------------------------\n",
      "Epoch 8\n",
      "Iteration 0 : 3.594942331314087\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction: ाााा ा ााा  ा  ा ाा      ा   ाहा      ा       ा    ा  ा  ा   े ा   ा     ा  ा      ा  ा     ााा   ीनननह ी  ह    क का ा        े  ा          ीाेाेेेेे  हहेााहाााााहकाेा    ा ााा  ााााा ा   ा  ााहााा   \n",
      "Evaluation translation (should we go to the mall?) : ('ाााा                                                                                                                                                       ााााा            ाा       ााााा              ',)\n",
      "-------------------------------------------\n",
      "Epoch 9\n",
      "Iteration 0 : 3.564627170562744\n",
      "English: presently elections are being held in gujarat.\n",
      "marathi Translation: दरम्यान, गुजरात निवडणूकीचा प्रचार आता शिगेला पोहोचला आहे.\n",
      "marathi Prediction:  ााा ा ा ा     ााा  ा    ा   ा ा   ा    ााा   ा  \n",
      "Evaluation translation (should we go to the mall?) : ('ाााा                                                                                                                                                       ाााााा           ाा      ाााााा       ाा     ',)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, mr_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, mr_batch)\n",
    "        optim.zero_grad()\n",
    "        mr_predictions = transformer(eng_batch,\n",
    "                                     mr_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(mr_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            mr_predictions.view(-1, mr_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == marathi_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"marathi Translation: {mr_batch[0]}\")\n",
    "            mr_sentence_predicted = torch.argmax(mr_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for idx in mr_sentence_predicted:\n",
    "              if idx == marathi_to_index[END_TOKEN]:\n",
    "                break\n",
    "              predicted_sentence += index_to_marathi[idx.item()]\n",
    "            print(f\"marathi Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            mr_sentence = (\"\",)\n",
    "            eng_sentence = (\"should we go to the mall?\",)\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, mr_sentence)\n",
    "                predictions = transformer(eng_sentence,\n",
    "                                          mr_sentence,\n",
    "                                          encoder_self_attention_mask.to(device), \n",
    "                                          decoder_self_attention_mask.to(device), \n",
    "                                          decoder_cross_attention_mask.to(device),\n",
    "                                          enc_start_token=False,\n",
    "                                          enc_end_token=False,\n",
    "                                          dec_start_token=True,\n",
    "                                          dec_end_token=False)\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_marathi[next_token_index]\n",
    "                mr_sentence = (mr_sentence[0] + next_token, )\n",
    "                if next_token == END_TOKEN:\n",
    "                  break\n",
    "            \n",
    "            print(f\"Evaluation translation (should we go to the mall?) : {mr_sentence}\")\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nosVPGVijId"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "ZOQe-juylBiJ"
   },
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "def translate(eng_sentence):\n",
    "  eng_sentence = (eng_sentence,)\n",
    "  mr_sentence = (\"\",)\n",
    "  for word_counter in range(max_sequence_length):\n",
    "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, mr_sentence)\n",
    "    predictions = transformer(eng_sentence,\n",
    "                              mr_sentence,\n",
    "                              encoder_self_attention_mask.to(device), \n",
    "                              decoder_self_attention_mask.to(device), \n",
    "                              decoder_cross_attention_mask.to(device),\n",
    "                              enc_start_token=False,\n",
    "                              enc_end_token=False,\n",
    "                              dec_start_token=True,\n",
    "                              dec_end_token=False)\n",
    "    next_token_prob_distribution = predictions[0][word_counter]\n",
    "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "    next_token = index_to_marathi[next_token_index]\n",
    "    mr_sentence = (mr_sentence[0] + next_token, )\n",
    "    if next_token == END_TOKEN:\n",
    "      break\n",
    "  return mr_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDVH_YsxlK6q",
    "outputId": "83c47f99-53c0-4c2d-c26a-aaa426f50563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ाााा                                                                                                                                                       ााााा            ाा       ाााा               \n"
     ]
    }
   ],
   "source": [
    "translation = translate(\"what should we do when the day starts?\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9yfawBnul0W",
    "outputId": "d9e6e6b7-683b-45f9-f013-c53c31038306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ाााा                                                                                                                                                       ाााााा           ाा      ाााााा              \n"
     ]
    }
   ],
   "source": [
    "translation = translate(\"how is this the truth?\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpdYBk5-urcQ",
    "outputId": "ca7249c5-efda-4f41-f052-ecef9691be82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ाााा                                                                                                                                                      ााााााा           ाा      ााााा         ््    \n"
     ]
    }
   ],
   "source": [
    "translation = translate(\"the world is a large place with different people\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzrOcNUk1-e5"
   },
   "source": [
    "## Experimentations left:\n",
    "\n",
    "- Using word-based or BPE based tokenizations or sentence piece.\n",
    "- Increase the number of encoder / decoder units for better translations. It was set to the minimum of 1 of each unit here.\n",
    "- layers, cross attn, self attn, multi attn and hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
